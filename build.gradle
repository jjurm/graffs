buildscript {
    repositories {
        mavenCentral()
    }
}

plugins {
    id 'java'
    id 'idea'
    id 'org.jetbrains.kotlin.jvm' version '1.3.50'
    id 'application'
    id 'com.palantir.git-version' version '0.12.2'
}

group 'uk.ac.cam.jm2186'
version '1.0-SNAPSHOT-' + gitVersion()

mainClassName = 'uk.ac.cam.jm2186.partii.JavaSparkPi'

sourceCompatibility = 1.8
targetCompatibility = 1.8

jar {
    manifest {
        attributes 'Main-Class': mainClassName
    }
    zip64 true
    // This line of code recursively collects and copies all of a project's files
    // and adds them to the JAR itself. One can extend this task, to skip certain
    // files or particular types at will
    from { configurations.compile.collect { it.isDirectory() ? it : zipTree(it) } }
}

def remoteWorkingDir = "/local/scratch/jm2186/partii-jars"

task jarUpload(type: Exec, dependsOn: jar) {
    commandLine "scp", "${buildDir}/libs/${archivesBaseName}-${version}.jar", "yellow:${remoteWorkingDir}"
}

task sparkSubmit(type: Exec, dependsOn: jarUpload) {
    commandLine "ssh", "yellow", "~/spark-2.4.4-bin-hadoop2.7/bin/spark-submit --deploy-mode client ${remoteWorkingDir}/${archivesBaseName}-${version}.jar"
}

test {
    useJUnitPlatform()
}

repositories {
    mavenCentral()
}

dependencies {
    compile "org.jetbrains.kotlin:kotlin-stdlib-jdk8"
    testImplementation "org.junit.jupiter:junit-jupiter:5.5.2"

    // https://mvnrepository.com/artifact/org.apache.commons/commons-lang3
    compile group: 'org.apache.commons', name: 'commons-lang3', version: '3.9'

    // https://mvnrepository.com/artifact/org.jgrapht/jgrapht-core
    compile group: 'org.jgrapht', name: 'jgrapht-core', version: '1.3.1'

    // https://mvnrepository.com/artifact/org.apache.spark/spark-sql
    compileOnly group: 'org.apache.spark', name: 'spark-sql_2.11', version: '2.4.4'
}

compileKotlin {
    kotlinOptions.jvmTarget = "1.8"
}
compileTestKotlin {
    kotlinOptions.jvmTarget = "1.8"
}
